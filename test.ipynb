{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmcao/.conda/envs/install/envs/oa_reactdiff/lib/python3.10/site-packages/torch_geometric/typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /home/xmcao/.conda/envs/install/envs/oa_reactdiff/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/home/xmcao/.conda/envs/install/envs/oa_reactdiff/lib/python3.10/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /home/xmcao/.conda/envs/install/envs/oa_reactdiff/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from oa.model import PaiNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PaiNN(num_feat=128, out_channels=128, in_hidden_channels=8, cutoff=5.0, n_rbf=20, num_interactions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = torch.rand(9, 8, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import radius_graph\n",
    "pos = torch.tensor([[ 0.0072, -0.5687,  0.0000],\n",
    "        [-1.2854,  0.2499,  0.0000],\n",
    "        [ 1.1304,  0.3147,  0.0000],\n",
    "        [ 0.0392, -1.1972,  0.8900],\n",
    "        [ 0.0392, -1.1972, -0.8900],\n",
    "        [-1.3175,  0.8784,  0.8900],\n",
    "        [-1.3175,  0.8784, -0.8900],\n",
    "        [-2.1422, -0.4239,  0.0000],\n",
    "        [ 1.9857, -0.1365,  0.0000]], dtype = torch.float)\n",
    "\n",
    "# edge_attr: inter_atomic distances\n",
    "edge_index = radius_graph(pos, r=1.70, batch=None, loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(s0, pos, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn import o3\n",
    "rot = o3.rand_matrix()\n",
    "pos_rot = pos @ rot\n",
    "edge_index_rot = radius_graph(pos_rot, r=1.70, batch=None, loop=False)\n",
    "out_rot = model(s0, pos_rot, edge_index_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.8429e-08, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out[1] @ rot - out_rot[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.5018e-07, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out[0] - out_rot[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.2919e-03, -5.6931e-01, -3.9026e-05],\n",
       "        [-1.2926e+00,  2.5303e-01, -8.8065e-04],\n",
       "        [ 1.1394e+00,  3.0648e-01,  1.3142e-04],\n",
       "        [ 3.9006e-02, -1.1940e+00,  8.8569e-01],\n",
       "        [ 3.8886e-02, -1.1922e+00, -8.8277e-01],\n",
       "        [-1.3173e+00,  8.7470e-01,  8.8491e-01],\n",
       "        [-1.3173e+00,  8.7461e-01, -8.8471e-01],\n",
       "        [-2.1386e+00, -4.2105e-01, -2.0991e-05],\n",
       "        [ 1.9787e+00, -1.3279e-01, -2.9483e-06]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import torch\n",
    "def compute_frag_index(atoms_mask_rtp: Tensor) -> np.ndarray:\n",
    "    counts = [\n",
    "        torch.where(atoms_mask_rtp == ii)[0].numel()\n",
    "        for ii in torch.unique(atoms_mask_rtp)\n",
    "    ]\n",
    "    return np.concatenate([np.array([0]), np.cumsum(counts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 6, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms_mask_rtp = torch.tensor([0, 0, 0, 0, 1, 1, 2, 2, 2], dtype=torch.long)\n",
    "compute_frag_index(atoms_mask_rtp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oa_reactdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
